---
title: "README"
output: html_notebook
---

Ã‰lida Silva Retamal

### Peer-graded Assignment: Getting and Cleaning Data Course Project

The purpose of the **Getting and Ceaning Data Course Project**, from the Coursera online platform, offered by Johns Hopkins University, aims to assess our ability to collect, work and clean a data set, in addition to verifying our ability to write a CodeBook and create a repository on GitHub.

Meeting the requirements of the evaluation criteria, we produce the following documents:

* An R script with the name **run_analysis.R**. 

* A **README.md** in the repository with the scripts, explaining how they work and are connected. 

* A code book describing the variables and transformations we did called **CodeBook.md**.

### The R script was created according to the rules provided for the project, that are:

##### Create one R script called run_analysis.R that does the following: 

- Step 1: Merges the training and the test sets to create one data set.
- Step 2: Extracts only the measurements on the mean and standard deviation for each measurement.
- Step 3: Uses descriptive activity names to name the activities in the data set
- Step 4: Appropriately labels the data set with descriptive variable names.
- Step 5: From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

=============================================================================================================

### Human Activity Recognition (HAR) Using Smartphones Dataset:

=============================================================================================================

#### Step 0. Getting, downloading, unzipping  and reading dataset

#### 0.1 - Getting the directory for the data:

```{r}
if (!file.exists("data")) {
    dir.create("data")
}
```

#### 0.2 - Dowloading the file:

```{r}
fileUrl <-"https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl, destfile = "./data/df1.zip")
```

#### 0.3 Unzip data set to data directory

```{r}
unzip(zipfile = "./data/df1.zip", exdir = "./data")
```

#### 0.4 Reading files and assigning column names:
#### 0.4.1 features:
```{r}
features <- read.table('./data/UCI HAR Dataset/features.txt', col.names = c("identifier", "signals"))
```

#### 0.4.2 activity_labels

```{r}
activities<- read.table("./data/UCI HAR Dataset/activity_labels.txt", col.names = c("activity","labels"))
```

#### 0.4.3 subject_train, X_train and y_train

```{r}
subject_train <- read.table("./data/UCI HAR Dataset/train/subject_train.txt", col.names = "subject")

X_train <- read.table("./data/UCI HAR Dataset/train/X_train.txt", col.names = features$signals)

y_train <- read.table("./data/UCI HAR Dataset/train/y_train.txt", col.names = "activity")
```

#### 0.4.4 subject_test, X_test and y_test

```{r}

subject_test <- read.table("./data/UCI HAR Dataset/test/subject_test.txt", col.names = "identifier")

X_test <- read.table("./data/UCI HAR Dataset/test/X_test.txt", col.names = features$signals)

y_test <- read.table("./data/UCI HAR Dataset/test/y_test.txt", col.names = "activity" )

```
#### 0.4.5 Size data set - Number rows and columns.
```{r}
dim(X_train) 
dim(y_train)  
dim(subject_train) 
dim(X_test) 
dim(y_test) 
dim(subject_test) 
dim(activities)
dim(features) 
```
#### Step 1.  Merges the training and the test sets to create one data set.
```{r}
my <- rbind(y_train, y_test); dim(my)
mX <- rbind(X_train, X_test); dim(mX)
msubject <- rbind(subject_train,subject_test); dim(msubject)
merge_dataset <- cbind(my, mX, msubject); dim(merge_dataset)
View(merge_dataset)
```

#### Step 2. Extracts only the measurements on the mean and standard deviation for each measurement.

#### 2.1 Tidy dataset:

```{r}
data_tidy <- merge_dataset %>%
    select(subject,
           activity,
           contains("mean"),
           contains("std"))
dim(data_tidy)
```
#### Step 3. Uses descriptive activity names to name the activities in the data set

```{r}
data_tidy$id <- activities[data_tidy$id, 2]
```
#### Step 4. Appropriately labels the data set with descriptive variable names.
#### 4.1  data_tidy lists names
```{r}
names(data_tidy)
```

#### 4.2 Names that will be replaced by descriptive names:

- t: Time
- f: Frequency
- Freq..: Frequency
- Acc: Accelerometer
- Gyro: Gyroscope
- Mag: Magnitude
- BodyBody: Body
- gravity: Gravity
- mean: Mean 

```{r}
names(data_tidy) <- gsub("Freq","Frequency",names(data_tidy), ignore.case = TRUE)
names(data_tidy) <- gsub("^t","Time",names(data_tidy))
names(data_tidy) <- sub(".tB","TimeB",names(data_tidy), ignore.case = FALSE)
names(data_tidy) <- gsub("^f","Frequency",names(data_tidy))
names(data_tidy) <- gsub("Acc","Accelerometer",names(data_tidy))
names(data_tidy) <- gsub("Mag","Magnitude",names(data_tidy))
names(data_tidy) <- gsub("gravity","Gravity",names(data_tidy))
names(data_tidy) <- gsub("Gyro","Gyroscope",names(data_tidy))
names(data_tidy) <- gsub("BodyBody","Body",names(data_tidy))
names(data_tidy) <- gsub("mean", "Mean", names(data_tidy))
```

#### 4.3  After changing data_tidy names:

```{r}
names(data_tidy)
```
#### 4.3  Having a look in data_tidy:

```{r}
head(data_tidy)
```

#### Step 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

```{r}
second_data <- data_tidy %>%
    group_by(subject, activity) %>%
    summarise_all(funs(mean))
```
```{r}
head(second_data)
